# -*- coding: utf-8 -*-
"""Copy of LA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_WRfsMbEvksYeazLA3S3ZZqal5LJ51b5
"""

import numpy as np
import os
import cv2 as cv
from google.colab.patches import cv2_imshow
import scipy.misc
import matplotlib

"""Training the system"""

def noise_generation(image, sigma):
   
    row,col= image.shape
    mean = 0
    
    gauss = np.random.normal(mean,sigma,(row,col))
    gauss = gauss.reshape(row,col)
    noised = image + gauss
    return noised

def Frobenius(A):
  At = A.T

  return np.trace(At@A)

def grayscale(image):
  return image @ [0.2126, 0.7152, 0.0722]

def error(A, A_approx):

  return Frobenius(np.subtract(A,A_approx))

def k_rank_approximation(svd,k, shape):
  U, s, Vt = svd

  sigma = np.zeros((shape[0],shape[1]))
  for i in range(min(shape[0],shape[1])):
    sigma[i,i] = s[i]

  approx_img = U @ sigma[:,:k] @ Vt[:k,:]
  return approx_img

path = "svd_example1.jpg"
cur_image = cv.imread(path)
cur_image = grayscale(cur_image)
svd = np.linalg.svd(cur_image)
# print(svd)
approx = k_rank_approximation(svd, 30, cur_image.shape)
cv2_imshow(approx)
print('\n')
cv2_imshow(cur_image)

def training(shape):
  max_sigma = 50
  sigma_step = 10
  imageQuantity = 2
  max_k = min(shape[0], shape[1])
  image_array = []

  for cur_image_index in range(1,imageQuantity+1):
    cur_image_path = f"svd_example{cur_image_index}.jpg"
    cur_image = cv.imread(cur_image_path)
    cur_image = grayscale(cur_image)
    image_array.append(cur_image)



  sigma_k_hash = {}

  for cur_sigma in np.arange(0, max_sigma, sigma_step):
    average_errors = []
    image_noisedSVD = []
    for image in image_array:
      noised_image = noise_generation(image, cur_sigma)
      svd = np.linalg.svd(noised_image)
      image_noisedSVD.append((image, svd))






    for cur_k in range(1,max_k+1):
      error_sum = 0
      error_count = 0

      for image_and_SVD in image_noisedSVD:

        cur_approx = k_rank_approximation(image_and_SVD[1], cur_k, image_and_SVD[0].shape)

        er = error(image_and_SVD[0], cur_approx)
        error_sum += er
        error_count += 1
      average_errors.append((error_sum/error_count, cur_k))




    sigma_k_hash[cur_sigma] = min(average_errors, key = lambda t: t[0])[1]
  return sigma_k_hash
cur_image_path = "svd_example1.jpg"
cur_image = cv.imread(cur_image_path)
image_type = cur_image.shape

sk = training(image_type)

sk

cur_image_path = "svd_example1.jpg"
cur_image = cv.imread(cur_image_path)
cur_image = grayscale(cur_image)
sigma = 10
k = 58
noised_image = noise_generation(cur_image, sigma)
svd = np.linalg.svd(noised_image)
approx = k_rank_approximation(svd, k, noised_image.shape)
print(error(cur_image, approx))
cv2_imshow(noised_image)
cv2_imshow(approx)
cv2_imshow(cur_image)

"""Denoising"""

def denoise(noised_image, sigma, sigma_k_hash):
  k = find_closest_sigma(sigma_k_hash, sigma)
  print(f"sigma: {sigma}, k: {k}")
  noised_svd = np.linalg.svd(noised_image)
  return k_rank_approximation(noised_svd, k, noised_image.shape)

def find_closest_sigma(sigma_k_hash, sigma):
  keys = np.array(list(sigma_k_hash.keys()))

  return sigma_k_hash[keys[(np.abs(keys - sigma)).argmin()]]

def generate_image():
  path = "test.jpg"
  cur_image = cv.imread(path)
  cur_image = grayscale(cur_image)
  return noise_generation(cur_image,10)

noised_image = generate_image()

def main(noised_image, sigma):
  sk = training(noised_image.shape)

  denoised = denoise(noised_image, sigma, sk)
  cv2_imshow(noised_image)
  cv2_imshow(denoised)
  return denoised

sigma = 10
main(noised_image, sigma)